{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aryanaryashrestha/a-b-testing-basics?scriptVersionId=172841891\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import binom\nfrom scipy.stats import chi2_contingency, mannwhitneyu, norm, t, ttest_ind\n\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"1. Discrete Metrics\nLet's consider first discrete metrics, e.g. click-though rate. We randomly show visitors one of two possible designs of an advertisement, and based on how many of them click on it we need to determine whether our data significantly contradict the hypothesis that the two designs are equivalently efficient.","metadata":{}},{"cell_type":"code","source":"np.random.seed(42)\n\nx = np.random.binomial(n=1, p=0.6, size=15)\ny = np.random.binomial(n=1, p=0.4, size=19)\n\n_, (a, c) = np.unique(x, return_counts=True)\n_, (b, d) = np.unique(y, return_counts=True)\n\ndf = pd.DataFrame(data=[[a, b], [c, d]], \n                 index=[\"click\", \"no click\"], \n                 columns=[\"A\", \"B\"])\nm = df.values\n\nprint(\"- Observations:\")\nprint(f\"  - Version A: = {x}\")\nprint(f\"  - Version B: = {y}\")\nprint(\"\")\nprint(\"- Contingency table:\")\ndisplay(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"1.1 Fisher's exact test\nSince we have a 2x2 contingency table we can use Fisher's exact test to compute an exact p-value and test our hypothesis.\n\n","metadata":{}},{"cell_type":"code","source":"def hypergeom(k, K, n, N):\n    \"\"\"Probability mass funciton of the hypergeometric distribution.\"\"\"\n    return binom(K, k) * binom(N-K, n-k) / binom(N, n)\n\n\ndef fisher_prob(m):\n    \"\"\"Probability of a given observed contingency table according to Fisher's exact test.\"\"\"\n    ((a, b), (c ,d)) = m\n    k = a\n    K = a+b\n    n = a+c\n    N = a+b+c+d\n    return hypergeom(k, K, n, N)\n\ndef fisher_probs_histogram(m):\n    \"\"\"Computes prob mass function histogram accroding to Fisher's exact test.\"\"\"\n    neg_val = -min(m[0,0], m[1,1])\n    pos_val = min(m[1,0], m[1,0])\n    probs = []\n    for k in range(neg_val, pos_val+1):\n        m1 = m + np.array([[1, -1], [-1, 1]]) * k\n        probs.append(fisher_prob(m1))\n    return probs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bars_h = np.array(fisher_probs_histogram(m))\n\nf, ax = plt.subplots(figsize=(6, 3))\nii = np.arange(len(bars_h))\nax.bar(ii, bars_h)\nidxs = bars_h <= fisher_prob(m)\nax.bar(ii[idxs], bars_h[idxs], color='r')\nax.set_ylabel(\"prob density\")\np_val = bars_h[idxs].sum()\nneg_val = -min(m[0,0], m[1,1])\npos_val = min(m[1,0], m[1,0])\nax.bar(ii[-neg_val], bars_h[-neg_val], color='orange')\n\nax.set_xticks(ii)\nax.set_xticklabels(np.arange(neg_val, pos_val+1))\nf.tight_layout()\nprint(f\"- Fisher's exact test: p-val = {100*p_val:.1f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"1.2 Pearson's chi-squared test\nFisher's exact test has the important advantage of computing exact p-values. But if we have a large sample size, it may be computationally inefficient. In this case, we can use Pearson's chi-squared test to compute an approximate p-value.","metadata":{}},{"cell_type":"code","source":"chi2_val, p_val = chi2_contingency(m, correction=False)[:2]\n\nprint(\"- Pearson's chi-squared t-test:\")\nprint(f\"   - χ2 value: {chi2_val:.3f}\")\nprint(f\"   - p-value: {p_val*100:.1f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"2. Continuous metrics\nLet's now consider the case of a continuous metrics, e.g. average revenue per user. We randomly show visitors of our website one of two possible layouts of products for sale, and based on how much revenue each user generated in a month we want to determine whether our data significantly contradict the hypothesis that the two website layouts are equivalently efficient.","metadata":{}},{"cell_type":"code","source":"np.random.seed(42)\n\nn_x, n_y = 17, 14\n\nd1 = norm(loc=200, scale=100)\nd2 = norm(loc=280, scale=90)\n\ndisc = 50\nx = (d1.rvs(size=n_x) / disc).astype(int) * disc\ny = (d2.rvs(size=n_y) / disc).astype(int) * disc\n\n\nprint(\"- Observations:\")\nprint(f\"  - Version A: = {x}\")\nprint(f\"  - Version B: = {y}\")\nprint(\"\")\nprint(f\"- Distribution plot:\")\nf, ax = plt.subplots(figsize=(6, 3))\nfor i, (x_, l_, c_) in enumerate(zip([x, y], [\"A\", \"B\"], [\"tab:blue\", \"tab:olive\"])):\n    v, c = np.unique(x_, return_counts=True)\n    ax.bar(v-5+10*i, c, width=10, label=l_, color=c_)\n\nax.set_xlabel(\"purchase in $\")\nax.set_ylabel(\"count\")\nax.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_pval(distribution, t_val, xlims=(-5, 5), ylims=(0, 0.5)):\n    xxx = np.linspace(*xlims, 1000)\n    f, ax = plt.subplots(figsize=(4,3))\n    ax.plot(xxx, distribution.pdf(xxx))\n    ax.set_ylim(ylims)\n    ax.vlines(t_val, 0, stat_distrib.pdf(t_val), color='orange')\n    ax.plot(t_val, stat_distrib.pdf(t_val), 'o', color='orange')\n    xp = xxx <= t_val\n    ax.fill_between(xxx[xp], xxx[xp] * 0, stat_distrib.pdf(xxx[xp]), color='r')\n    xp = xxx >= -t_val\n    ax.fill_between(xxx[xp], xxx[xp] * 0, stat_distrib.pdf(xxx[xp]), color='r')\n    ax.set_ylabel(\"prob denisty\")\n    f.tight_layout()\n    return f, ax","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"2.1 Z-test\nThe Z-test can be applied under the following assumptions.\n\nThe observations are normally distributed (or the sample size is large).\nThe sampling distributions have known variance σ_X and σ_Y.\nUnder the above assumptions, the Z-test relies on the observation that the following Z statistic has a standard normal distribution.\n\n","metadata":{}},{"cell_type":"code","source":"# Known standard deviations\ns_x = 100\ns_y = 90\n\n# Z value\nz_val = (x.mean() - y.mean()) / np.sqrt(s_x**2/n_x + s_y**2/n_y)\n\n# Test statistic distribution under null hypothesis H0\nstat_distrib = norm(loc=0, scale=1)\n\n# p-value\np_val = stat_distrib.cdf(z_val) * 2\n\nprint(\"- Z-test:\")\nprint(f\"   - z value: {z_val:.3f}\")\nprint(f\"   - p-value: {p_val*100:.1f}%\")\nplot_pval(stat_distrib, z_val);\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"2.2 Student's t-test\nIn most cases, the variances of the sampling distributions are unknown, so that we need to estimate them. Student's t-test can then be applied under the following assumptions.\n\nThe observations are normally distributed (or the sample size is large).\nThe sampling distributions have \"similar\" variances σX ≈ σY.\nUnder the above assumptions, Student's t-test relies on the observation that the following t statistic has a Student's t distribution.","metadata":{}},{"cell_type":"code","source":"# Sample variances (w. Bessel correction)\ns_x = np.sqrt(np.var(x, ddof=1))\ns_y = np.sqrt(np.var(y, ddof=1))\n\n# Pooled variance\ns_p = np.sqrt(((n_x-1) * s_x**2 +\n               (n_y-1) * s_y**2)\n              / (n_x + n_y - 2))\n\n# Test statistic distribution under null hypothesis H0\ndofs = n_x + n_y - 2\nstat_distrib = t(df=dofs, loc=0, scale=1)\n\n# t value\nt_val = (x.mean() - y.mean()) / (s_p * np.sqrt(1/n_x + 1/n_y))\n\n# p-value\np_val = stat_distrib.cdf(t_val) * 2\n\nprint(\"- Student's t-test:\")\nprint(f\"   - nu: {dofs:.3f}\")\nprint(f\"   - t value: {t_val:.3f}\")\nprint(f\"   - p-value: {p_val*100:.1f}%\")\nplot_pval(stat_distrib, z_val);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"2.3 Welch's t-test\nIn most cases Student's t test can be effectively applied with good results. However, it may rarely happen that its second assumption (similar variance of the sampling distributions) is violated. In that case, we cannot compute a pooled variance and rather than Student's t test we should use Welch's t-test.\n\nThis test operates under the same assumptions of Student's t-test but removes the requirement on the similar variances. Then, we can use a slightly different t statistic, which also has a Student's t distribution, but with a different number of degrees of freedom ν.","metadata":{}},{"cell_type":"code","source":"# Sample variances (w. Bessel correction)\ns_x = np.sqrt(np.var(x, ddof=1))\ns_y = np.sqrt(np.var(y, ddof=1))\n\n# Denominator (not a pooled variance!)\ns_d = np.sqrt(s_x**2/n_x + s_y**2/n_y)\n    \n    \n# Test statistic distribution under null hypothesis H0\ndofs = s_d**4 / ((s_x**2/n_x)**2/(n_x-1) +\n                 (s_y**2/n_y)**2/(n_y-1))\nstat_distrib = t(df=dofs, loc=0, scale=1)\n\n# t value\nt_val = (x.mean() - y.mean()) / s_d\n\n# p-value\np_val = stat_distrib.cdf(t_val) * 2\n\nprint(\"- Welch' t-test:\")\nprint(f\"   - nu: {dofs:.3f}\")\nprint(f\"   - t value: {t_val:.3f}\")\nprint(f\"   - p-value: {p_val*100:.1f}%\")\nplot_pval(stat_distrib, z_val);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"2.4 Mann-Whitney U test\nThis test makes the least assumptions about the nature of our observations, as it is fully nonparametric. The idea of Mann-Whitney U test is to compute the U statistic.\n\nThe values of this test statistic are tabulated, as the distribution can be computed under the null hypothesis that, for random samples X and Y from the two populations, the probability P(X < Y) is the same as P(X > Y).","metadata":{}},{"cell_type":"code","source":"mwu = mannwhitneyu(x, y, use_continuity=False, alternative=\"two-sided\")\n\nprint(\"- Mann-Whitney U test:\")\nprint(f\"   - U value: {mwu.statistic:.3f}\")\nprint(f\"   - p-value: {mwu.pvalue*100:.1f}%\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"3. Data distribution VS Stats distribution\nTests that rely on the assumption of normally distributed test statistics can also be applied if the original sampling distribution is highly non-normal!\n\nIndeed, thanks to the Central Limit Theorem, the distribution of the test statistic is asymptotically normal as the sample size increases.\n\nThis is very useful in the common case of A/B tests that produce observations that are zero-inflated and/or multimodal.","metadata":{}},{"cell_type":"code","source":"p = np.array([245, 0, 0, 0, 0, 0, 0, 0, 0,  1, 3, 1, 3, 2, 9, 18, 22, 10, 6, 2, 2, 1, 2, 1, 1])\na = np.arange(len(p))\np = p / p.sum()\n\nf, ax = plt.subplots(figsize=(6, 3))\nax.bar(a, p)\nax.set_ylabel(\"prob density\")\nax.set_xlabel(\"x\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loc = (p*np.arange(len(p))).sum()\n\nnn = [1, 10, 20, 40]\nf, axx = plt.subplots(2, 2, figsize=(3.5*2, 2.3*2))    \n\nfor i, n in enumerate(nn):\n    r, c = divmod(i, 2)        \n    x = p\n    ax = axx[r, c]\n    for _ in range(n):\n        x = np.convolve(x, p)\n\n    ax.bar(np.arange(len(x))/n, x*n, width=1/n)\n    ax.set_ylim([0, 0.51])\n    ax.vlines(loc, 0, 0.51, 'r')\n    ax.set_xlabel(\"test statistic\")\n    ax.set_ylabel(\"prob density\")\n    ax.set_title(f\"sample size = {n}\")\n\nf.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}